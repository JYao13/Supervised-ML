{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing, svm, neighbors\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclid Dist: 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# definition of the euclidean distance\n",
    "\n",
    "plot1 = [1,3]\n",
    "plot2 = [2,5]\n",
    "\n",
    "euclid_dist = sqrt((plot1[0]-plot2[0])**2 + (plot1[1]-plot2[1])**2) # square root of (x1-x2)^2 + (y1-y2)^2\n",
    "print('Euclid Dist: ' + str(euclid_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating some sample data - \"coordinates\" in 2D - will be our features for KNN\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3], [3,1]], 'r':[[6,5],[7,7],[8,6]]} # two sets of groups of coordinates - features\n",
    "\n",
    "new_features = [5,7] # a new coordinate - which group does this belong to, k or r? - likely r by observation\n",
    "\n",
    "# plot all points in the group\n",
    "\n",
    "for group in dataset:\n",
    "    for feature in dataset[group]:\n",
    "        plt.scatter(feature[0], feature[1], s=100, color=group)\n",
    "\n",
    "plt.scatter(new_features[0], new_features[1], s=100) # plot the new point\n",
    "plt.show()\n",
    "\n",
    "# blue point does indeed appear to be part of r group just by proximity to r features - apply k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining k nearest neighbors algorithm\n",
    "# pass data to trai against, new data we want to predict, k value\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K set to value less than total voting groups!')\n",
    "        \n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclid_dist = np.linalg.norm(np.array(features)-np.array(predict)) # lin alg way of euclid dist\n",
    "            distances.append([euclid_dist, group])\n",
    "    \n",
    "    votes = [i[1] for i in sorted(distances)[:k]] # get kth top distances\n",
    "    vote_result = Counter(votes).most_common(1)[0][0] # 1st most common group in votes\n",
    "    confidence = Counter(votes).most_common(1)[0][1] / k\n",
    "    \n",
    "    return vote_result, confidence\n",
    "\n",
    "# we are just finding the distances from new point to every point in training data, classified by existing group\n",
    "# we then sort this list to get the shortest distances and find the most common group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r', 1.0)\n"
     ]
    }
   ],
   "source": [
    "result = k_nearest_neighbors(dataset, new_features, 3)\n",
    "print(result) # we've predicted that the new point (new_features), belongs in r type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645\n",
      "0.865\n",
      "0.91\n",
      "0.525\n",
      "0.81\n",
      "0.635\n",
      "0.63\n",
      "0.89\n",
      "0.92\n",
      "0.83\n",
      "0.78\n",
      "0.605\n",
      "0.6\n",
      "0.53\n",
      "0.75\n",
      "0.755\n",
      "0.58\n",
      "0.58\n",
      "0.52\n",
      "0.62\n",
      "0.545\n",
      "0.835\n",
      "0.92\n",
      "0.635\n",
      "0.69\n",
      "0.765\n",
      "0.89\n",
      "0.67\n",
      "0.89\n",
      "0.915\n",
      "0.965\n",
      "0.555\n",
      "0.65\n",
      "0.605\n",
      "0.82\n",
      "0.84\n",
      "0.775\n",
      "0.72\n",
      "0.575\n",
      "0.575\n",
      "0.635\n",
      "0.61\n",
      "0.935\n",
      "0.84\n",
      "0.97\n",
      "0.98\n",
      "0.75\n",
      "0.89\n",
      "0.775\n",
      "0.53\n",
      "0.94\n",
      "0.75\n",
      "0.755\n",
      "0.81\n",
      "0.92\n",
      "0.885\n",
      "0.985\n",
      "0.88\n",
      "0.575\n",
      "0.84\n",
      "0.805\n",
      "0.915\n",
      "0.655\n",
      "0.645\n",
      "0.98\n",
      "0.59\n",
      "0.815\n",
      "0.89\n",
      "0.645\n",
      "0.52\n",
      "0.91\n",
      "0.845\n",
      "0.925\n",
      "0.985\n",
      "0.81\n",
      "0.59\n",
      "0.625\n",
      "0.96\n",
      "0.815\n",
      "0.8\n",
      "0.77\n",
      "0.975\n",
      "0.995\n",
      "0.88\n",
      "0.915\n",
      "0.815\n",
      "0.55\n",
      "0.57\n",
      "0.79\n",
      "0.65\n",
      "0.92\n",
      "0.67\n",
      "0.75\n",
      "0.925\n",
      "0.88\n",
      "0.955\n",
      "0.88\n",
      "0.555\n",
      "0.57\n",
      "0.615\n",
      "0.62\n",
      "0.735\n",
      "0.745\n",
      "0.75\n",
      "0.68\n",
      "0.56\n",
      "0.91\n",
      "0.59\n",
      "0.6\n",
      "0.67\n",
      "0.945\n",
      "0.955\n",
      "0.985\n",
      "0.595\n",
      "0.8\n",
      "0.63\n",
      "0.645\n",
      "0.855\n",
      "0.535\n",
      "0.74\n",
      "0.995\n",
      "0.955\n",
      "0.93\n",
      "0.59\n",
      "0.655\n",
      "0.66\n",
      "0.635\n",
      "0.93\n",
      "0.97\n",
      "0.9\n",
      "0.615\n",
      "0.65\n",
      "0.605\n",
      "0.725\n",
      "0.845\n",
      "0.545\n",
      "0.895\n",
      "0.64\n",
      "0.975\n",
      "0.625\n",
      "0.655\n",
      "0.96\n",
      "0.675\n",
      "0.62\n",
      "0.62\n",
      "0.925\n",
      "0.935\n",
      "0.575\n",
      "0.885\n",
      "0.64\n",
      "0.965\n",
      "0.715\n",
      "0.775\n",
      "0.525\n",
      "0.755\n",
      "0.855\n",
      "0.64\n",
      "0.915\n",
      "0.875\n",
      "0.985\n",
      "0.745\n",
      "0.615\n",
      "0.97\n",
      "0.87\n",
      "0.815\n",
      "0.605\n",
      "0.64\n",
      "0.75\n",
      "0.98\n",
      "0.63\n",
      "0.905\n",
      "0.74\n",
      "0.58\n",
      "0.655\n",
      "0.91\n",
      "0.92\n",
      "0.91\n",
      "0.715\n",
      "0.64\n",
      "0.875\n",
      "0.73\n",
      "0.73\n",
      "0.76\n",
      "0.795\n",
      "0.91\n",
      "0.815\n",
      "0.67\n",
      "0.91\n",
      "0.505\n",
      "0.645\n",
      "0.96\n",
      "0.86\n",
      "0.935\n",
      "0.8\n",
      "0.62\n",
      "0.88\n",
      "0.91\n",
      "0.86\n",
      "0.66\n",
      "0.6\n",
      "0.96\n",
      "0.84\n",
      "0.635\n",
      "0.705\n",
      "0.98\n",
      "0.525\n",
      "0.88\n",
      "0.905\n",
      "0.885\n",
      "0.63\n",
      "0.98\n",
      "Accuracies:  0.9392805755395683\n"
     ]
    }
   ],
   "source": [
    "# our model\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(25):\n",
    "    # pulling UCI breast cancer data from directory\n",
    "    df = pd.read_csv(r\"breast-cancer-wisconsin.data\")\n",
    "\n",
    "    # editing df\n",
    "    df.replace('?', -99999, inplace=True)\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "    full_data = df.astype(float).values.tolist()\n",
    "\n",
    "    random.shuffle(full_data)\n",
    "    # creating training and testing data\n",
    "\n",
    "    test_size = 0.2 # 20% of data reserved to test on\n",
    "    train_set = {2:[], 4:[]} # 2 or 4 -> 2 = non-cancerous, 4 = cancerous\n",
    "    test_set = {2:[], 4:[]}\n",
    "\n",
    "    train_data = full_data[:-int(test_size*len(full_data))]\n",
    "    test_data = full_data[-int(test_size*len(full_data)):]\n",
    "\n",
    "    for i in train_data:\n",
    "        train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    for i in test_data:\n",
    "        test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "    # applying k_nearest neighbors\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for group in test_set:\n",
    "        for data in test_set[group]: # group will be 2 or 4\n",
    "            vote, confidence = k_nearest_neighbors(train_set, data, k=200)\n",
    "            if group == vote:\n",
    "                correct += 1\n",
    "            else:\n",
    "                print(confidence)\n",
    "            total += 1\n",
    "    accuracies.append(correct/total)\n",
    "\n",
    "print('Accuracies: ', sum(accuracies)/len(accuracies)) # how many tests we perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969142857142857\n"
     ]
    }
   ],
   "source": [
    "# compare to k_nearest neighbors algorithm\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    # pulling data from directory\n",
    "    df = pd.read_csv(r\"breast-cancer-wisconsin.data\")\n",
    "\n",
    "    # editing df\n",
    "    df.replace('?', -99999, inplace=True)\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    X = np.array(df.drop(columns=['class'])) # feature\n",
    "    y = np.array(df['class']) # class/label\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "    clf = neighbors.KNeighborsClassifier() # k-nearest neighbors classifier from sklearn\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(sum(accuracies)/len(accuracies)) # how many tests we perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model - testing\n",
    "\n",
    "# pulling data from directory\n",
    "df = pd.read_csv(r\"breast-cancer-wisconsin.data\")\n",
    "\n",
    "# editing df\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "full_data = df.astype(float).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(full_data)\n",
    "# creating training and testing data\n",
    "\n",
    "test_size = 0.2 # 20% of data reserved to test on\n",
    "train_set = {2:[], 4:[]} # 2 or 4 -> 2 = non-cancerous, 4 = cancerous\n",
    "test_set = {2:[], 4:[]}\n",
    "\n",
    "train_data = full_data[:-int(test_size*len(full_data))]\n",
    "test_data = full_data[-int(test_size*len(full_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "0.905\n",
      "0.645\n",
      "0.625\n",
      "0.875\n",
      "0.53\n",
      "Accuracy:  0.9568345323741008\n"
     ]
    }
   ],
   "source": [
    "# populating our dictionaries\n",
    "\n",
    "# train_set[i[-1]] will be 2 or 4 (last column of set)\n",
    "# we will use this as id to merge into our dictionaries, where this is a key\n",
    "# we populate (merge) all data (bunch of lists) up to the classifier\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "# applying k_nearest neighbors\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]: # group will be 2 or 4\n",
    "        vote, confidence = k_nearest_neighbors(train_set, data, k=200)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(confidence)\n",
    "        total += 1\n",
    "print('Accuracy: ', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.53)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest_neighbors(train_set, data, k=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
